{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import os\n",
    "import einops\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from   keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv(\"./MNIST Dataset/sign_mnist_train.csv\")\n",
    "test       = pd.read_csv(\"./MNIST Dataset/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "np.save(\"./labels.npy\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train_full.values[:,1:].astype(np.float32())\n",
    "y_train_full = train_full.values[:,0]\n",
    "X_test = test.values[:,1:].astype(np.float32())\n",
    "y_test = test.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting validation set from the training set using stratified splitting\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 2500)\n",
    "for train_index, test_index in split.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full[train_index], X_train_full[test_index]\n",
    "    y_train, y_val = y_train_full[train_index], y_train_full[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the csv files as .avi files\n",
    "letter_storage  = np.zeros(len(label_map), dtype = np.int16)\n",
    "train_sequences = [0] * X_train.shape[0]\n",
    "test_sequences  = [0] * X_test.shape[0]\n",
    "val_sequences   = [0] * X_val.shape[0]\n",
    "temp_sequence   = [0] * 30\n",
    "size = (28, 28)\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./MNIST Images/\")\n",
    "    os.mkdir(\"./MNIST Images/train/\")\n",
    "    os.mkdir(\"./MNIST Images/test/\")\n",
    "    os.mkdir(\"./MNIST Images/val/\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "\n",
    "# Creates the training sequences\n",
    "for i in range(0, X_train.shape[0]):\n",
    "    path = \"./MNIST Images/train/\" + label_map[y_train[i]] + \"/\"\n",
    "    name = str(letter_storage[y_train[i]]) + \".avi\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        pass\n",
    "    result = cv.VideoWriter(path + name, cv.VideoWriter_fourcc(*\"MJPG\"), 30, size)\n",
    "    letter_storage[y_train[i]] += 1\n",
    "    for j in range(0, 30):\n",
    "        temp_sequence[j] = X_train[i]\n",
    "    result.write(np.array(temp_sequence))\n",
    "    train_sequences[i] = temp_sequence\n",
    "\n",
    "# Creates the test sequences\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    path = \"./MNIST Images/test/\" + label_map[y_test[i]] + \"/\"\n",
    "    name = str(letter_storage[y_test[i]]) + \".avi\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        pass\n",
    "    result = cv.VideoWriter(path + name, cv.VideoWriter_fourcc(*\"MJPG\"), 30, size)\n",
    "    for j in range(0, 30):\n",
    "        temp_sequence[j] = X_test[i]\n",
    "    result.write(np.array(temp_sequence))\n",
    "    test_sequences[i] = temp_sequence\n",
    "\n",
    "# Creates the val sequences\n",
    "for i in range(0, X_val.shape[0]):\n",
    "    path = \"./MNIST Images/val/\" + label_map[y_val[i]] + \"/\"\n",
    "    name = str(letter_storage[y_val[i]]) + \".avi\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        pass\n",
    "    result = cv.VideoWriter(path + name, cv.VideoWriter_fourcc(*\"MJPG\"), 30, size)\n",
    "    for j in range(0, 30):\n",
    "        temp_sequence[j] = X_val[i]\n",
    "    result.write(np.array(temp_sequence))\n",
    "    val_sequences[i] = temp_sequence\n",
    "\n",
    "train_sequences = np.array(train_sequences)\n",
    "test_sequences  = np.array(test_sequences)\n",
    "val_sequences   = np.array(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates frames\n",
    "class FrameGenerator:\n",
    "    def __init__(self, n_frames, training = False):\n",
    "        \"\"\"\n",
    "        Returns a set of frames with their associated label.\n",
    "        @param n_frames: Number of frames.\n",
    "        @param training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def __call__(self):\n",
    "        video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "        pairs = list(zip(video_paths, classes))\n",
    "\n",
    "        if self.training:\n",
    "            random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames) \n",
    "            label = self.class_ids_for_name[name] # Encode labels\n",
    "            yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 30\n",
    "batch_size = 16\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths[\"train\"], n_frames, training=True),\n",
    "                                          output_signature = output_signature)\n",
    "\n",
    "# Batch the data\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths[\"val\"], n_frames),\n",
    "                                        output_signature = output_signature)\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths[\"test\"], n_frames),\n",
    "                                         output_signature = output_signature)\n",
    "\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        \"\"\"\n",
    "        A sequence of convolutional layers that first apply the convolution operation over the spatial dimensions, and then the temporal dimension. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([  \n",
    "            # Spatial decomposition\n",
    "            layers.Conv3D(filters = filters,\n",
    "                            kernel_size = (1, kernel_size[1], kernel_size[2]),\n",
    "                            padding = padding),\n",
    "\n",
    "            # Temporal decomposition\n",
    "            layers.Conv3D(filters = filters, \n",
    "                            kernel_size = (kernel_size[0], 1, 1),\n",
    "                            padding = padding)\n",
    "            ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualMain(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Residual block of the model with convolution, layer normalization, and the activation function, ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters = filters,\n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters = filters, \n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Project(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Project certain dimensions of the tensor as the data is passed through different sized filters and downsampled. \n",
    "    \"\"\"\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_residual_block(input, filters, kernel_size):\n",
    "    \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data and filter size does not match, project it such that last dimension matches.\n",
    "    \"\"\"\n",
    "    out = ResidualMain(filters, kernel_size)(input)\n",
    "    res = input\n",
    "\n",
    "    # Using the Keras functional APIs, project the last dimension of the tensor to match the new filter size\n",
    "    if out.shape[-1] != input.shape[-1]:\n",
    "        res = Project(out.shape[-1])(res)\n",
    "\n",
    "    return layers.add([res, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        \"\"\"\n",
    "        Use the einops library to resize the tensor.\n",
    "        @param video: Tensor representation of the video, in the form of a set of frames.\n",
    "        @return A downsampled size of the video according to the new height and width it should be resized to.\n",
    "        \"\"\"\n",
    "        # b stands for batch size, t stands for time, h stands for height, w stands for width, and c stands for the number of channels.\n",
    "        old_shape = einops.parse_shape(video, \"b t h w c\")\n",
    "        images = einops.rearrange(video, \"b t h w c -> (b t) h w c\")\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(\n",
    "        images, \"(b t) h w c -> b t h w c\",\n",
    "        t = old_shape[\"t\"])\n",
    "        return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 28\n",
    "WIDTH  = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 28, 28,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2_plus1d (Conv2Plus1D)     (None, 10, 28, 28,   3152        ['input_1[0][0]']                \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 10, 28, 28,   64         ['conv2_plus1d[0][0]']           \n",
      " alization)                     16)                                                               \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 10, 28, 28,   0           ['batch_normalization[0][0]']    \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)     (None, 10, 14, 14,   0           ['re_lu[0][0]']                  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " residual_main (ResidualMain)   (None, 10, 14, 14,   6272        ['resize_video[0][0]']           \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 10, 14, 14,   0           ['resize_video[0][0]',           \n",
      "                                16)                               'residual_main[0][0]']          \n",
      "                                                                                                  \n",
      " resize_video_1 (ResizeVideo)   (None, 10, 7, 7, 16  0           ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " project (Project)              (None, 10, 7, 7, 32  608         ['resize_video_1[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualMain)  (None, 10, 7, 7, 32  20224      ['resize_video_1[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 10, 7, 7, 32  0           ['project[0][0]',                \n",
      "                                )                                 'residual_main_1[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVideo)   (None, 10, 3, 3, 32  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " project_1 (Project)            (None, 10, 3, 3, 64  2240        ['resize_video_2[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " residual_main_2 (ResidualMain)  (None, 10, 3, 3, 64  80384      ['resize_video_2[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 10, 3, 3, 64  0           ['project_1[0][0]',              \n",
      "                                )                                 'residual_main_2[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_3 (ResizeVideo)   (None, 10, 1, 1, 64  0           ['add_2[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " project_2 (Project)            (None, 10, 1, 1, 12  8576        ['resize_video_3[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " residual_main_3 (ResidualMain)  (None, 10, 1, 1, 12  320512     ['resize_video_3[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 10, 1, 1, 12  0           ['project_2[0][0]',              \n",
      "                                8)                                'residual_main_3[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling3d (Glob  (None, 128)         0           ['add_3[0][0]']                  \n",
      " alAveragePooling3D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['global_average_pooling3d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           1290        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 443,322\n",
      "Trainable params: 443,290\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (None, 10, HEIGHT, WIDTH, 3)\n",
    "input = layers.Input(shape = (input_shape[1:]))\n",
    "x = input\n",
    "\n",
    "x = Conv2Plus1D(filters = 16, kernel_size = (3, 7, 7), padding = \"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = ResizeVideo(HEIGHT // 2, WIDTH // 2)(x)\n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 16, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x, 32, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
    "\n",
    "# Block 4\n",
    "x = add_residual_block(x, 128, (3, 3, 3))\n",
    "\n",
    "x = layers.GlobalAveragePooling3D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(input, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the optimizer\n",
    "customOptimizer = keras.optimizers.Adam(5e-4)\n",
    "\n",
    "# Defines the loss function\n",
    "customLoss = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Defines the callbacks to include\n",
    "my_callbacks = [\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath = \"./MNIST Models 2D/Accuracy/mnist_detection.acc.{epoch:02d}-{val_accuracy:.2f}.h5\", monitor = \"val_accuracy\", mode = \"max\", save_best_only = True),\n",
    "    #tf.keras.callbacks.ModelCheckpoint(filepath = \"./MNIST Models 2D/Loss/mnist_detection.loss.{epoch:02d}-{val_loss:.2f}.h5\", monitor = \"val_loss\", mode = \"min\", save_best_only = True),\n",
    "    tf.keras.callbacks.EarlyStopping  (patience = 200, monitor = \"accuracy\"),\n",
    "    #tf.keras.callbacks.TensorBoard    (log_dir  = \"./Logs\")\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = customLoss, optimizer = customOptimizer, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the model\n",
    "history = model.fit(x = train_ds, epochs = 10, validation_data = val_ds, callbacks = my_callbacks, use_multiprocessing = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Plotting training and validation learning curves.\n",
    "    @param history: model history with all the metric measures\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    # Plot loss\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.plot(history.history[\"loss\"], label = \"train\")\n",
    "    ax1.plot(history.history[\"val_loss\"], label = \"test\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    # Determine upper bound of y-axis\n",
    "    max_loss = max(history.history[\"loss\"] + history.history[\"val_loss\"])\n",
    "\n",
    "    ax1.set_ylim([0, np.ceil(max_loss)])\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.legend([\"Train\", \"Validation\"]) \n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.plot(history.history[\"accuracy\"],  label = \"train\")\n",
    "    ax2.plot(history.history[\"val_accuracy\"], label = \"test\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset): \n",
    "    \"\"\"\n",
    "    Creates a list of actual ground truth values and the predictions from the model.\n",
    "    @param dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "    @return Ground truth and predicted values for a particular dataset.\n",
    "    \"\"\"\n",
    "    actual = [labels for _, labels in dataset.unbatch()]\n",
    "    predicted = model.predict(dataset)\n",
    "\n",
    "    actual = tf.stack(actual, axis=0)\n",
    "    predicted = np.concatenate(predicted, axis = 0)\n",
    "    predicted = np.argmax(predicted, axis = 1)\n",
    "\n",
    "    return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = tf.math.confusion_matrix(actual, predicted)\n",
    "    ax = sns.heatmap(cm, annot = True, fmt = \"g\")\n",
    "    sns.set(rc={\"figure.figsize\":(12, 12)})\n",
    "    sns.set(font_scale=1.4)\n",
    "    ax.set_title(\"Confusion matrix of action recognition for \" + ds_type)\n",
    "    ax.set_xlabel(\"Predicted Action\")\n",
    "    ax.set_ylabel(\"Actual Action\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(y_actual, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Calculate the precision and recall of a classification model using the ground truth and predicted values.\n",
    "    @param y_actual: Ground truth labels.\n",
    "    @param y_pred: Predicted labels.\n",
    "    @param labels: List of classification labels.\n",
    "    @return Precision and recall measures.\n",
    "    \"\"\"\n",
    "    cm = tf.math.confusion_matrix(y_actual, y_pred)\n",
    "    tp = np.diag(cm) # Diagonal represents true positives\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(len(labels)):\n",
    "        col = cm[:, i]\n",
    "        fp = np.sum(col) - tp[i] # Sum of column minus true positive is false negative\n",
    "\n",
    "        row = cm[i, :]\n",
    "        fn = np.sum(row) - tp[i] # Sum of row minus true positive, is false negative\n",
    "\n",
    "        precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision \n",
    "\n",
    "        recall[labels[i]] = tp[i] / (tp[i] + fn) # Recall\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the results of the training\n",
    "actual, predicted = get_actual_predicted_labels(train_ds)\n",
    "plot_confusion_matrix(actual, predicted, labels, \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the results of the testing\n",
    "actual, predicted = get_actual_predicted_labels(test_ds)\n",
    "plot_confusion_matrix(actual, predicted, labels, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates precission and recall\n",
    "precision, recall = calculate_classification_metrics(actual, predicted, labels) # Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c4d8d893f66a00c95942b473020bc4ff2b3586422a214c9e49bf270ef10dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
