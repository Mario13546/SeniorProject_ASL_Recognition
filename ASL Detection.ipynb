{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ASL Detector Training</h1>\n",
    "<p>Created by Alex Pereira</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow import keras\n",
    "from   tensorflow.keras.utils  import to_categorical\n",
    "from   sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets variables for data collection\n",
    "DATA_PATH    = os.path.join(\"MP_Data\")\n",
    "action_list  = np.load(\"actions.npy\")  # List of gestures\n",
    "num_videos   = 30  # Number of videos\n",
    "video_frames = 30  # Frames per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a label map\n",
    "label_map = {label:num for num, label in enumerate(action_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "# \n",
    "for action in action_list:\n",
    "    # \n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        # \n",
    "        window = []\n",
    "\n",
    "        # \n",
    "        for num_frame in range(0, video_frames):\n",
    "            frame = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(num_frame)))\n",
    "            window.append(frame)\n",
    "\n",
    "        #\n",
    "        sequences.append(window)\n",
    "\n",
    "        # \n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a numpy array\n",
    "X = np.array(sequences)\n",
    "\n",
    "# Stores the labels in an array\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Creation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model building components\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds layers to the model\n",
    "model.add(LSTM(64,  return_sequences = True , activation = \"relu\", input_shape = (30,1662)))\n",
    "model.add(LSTM(128, return_sequences = True , activation = \"relu\"))\n",
    "model.add(LSTM(64,  return_sequences = False, activation = \"relu\"))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dense(action_list.shape[0], activation = \"softmax\"))\n",
    "\n",
    "# Print a model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the optimizer\n",
    "customOptimizer = keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Defines the loss function\n",
    "customLoss      = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Defines the callbacks to include\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath = \"asl_accuracy/asl_detection.acc.{epoch:02d}-{cat_accuracy:.2f}.h5\", monitor = \"val_cat_accuracy\", mode = \"max\", save_best_only = True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath = \"asl_loss/asl_detection.loss.{epoch:02d}-{val_loss:.2f}.h5\", monitor = \"loss\", mode = \"min\", save_best_only = True),\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 500, monitor = \"cat_accuracy\"),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir  = \"Logs\")\n",
    "]\n",
    "\n",
    "# Creates customized metrics\n",
    "custom_metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(name = \"cat_accuracy\", dtype = None)\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = customOptimizer, loss = customLoss, metrics = custom_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 5000, callbacks = my_callbacks, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Accuracy Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesary imports\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain some predictions\n",
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the predictions\n",
    "ytrue = np.argmax(y_test, axis = 1).tolist()\n",
    "yhat  = np.argmax(yhat  , axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess accuracy\n",
    "accuracy_score(ytrue, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03c4d8d893f66a00c95942b473020bc4ff2b3586422a214c9e49bf270ef10dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
